{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a14052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\n",
      "Current sys.path:\n",
      "  c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\n",
      "  c:\\Users\\asus\\anaconda3\\python313.zip\n",
      "  c:\\Users\\asus\\anaconda3\\DLLs\n",
      "  c:\\Users\\asus\\anaconda3\\Lib\n",
      "  c:\\Users\\asus\\anaconda3\n",
      "  \n",
      "  c:\\Users\\asus\\anaconda3\\Lib\\site-packages\n",
      "  c:\\Users\\asus\\anaconda3\\Lib\\site-packages\\win32\n",
      "  c:\\Users\\asus\\anaconda3\\Lib\\site-packages\\win32\\lib\n",
      "  c:\\Users\\asus\\anaconda3\\Lib\\site-packages\\Pythonwin\n",
      "clean_text is callable and loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import nltk \n",
    "\n",
    "\n",
    "try:\n",
    "    notebook_path = os.path.abspath('') \n",
    "except NameError:\n",
    "    notebook_path = os.getcwd() \n",
    "\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Added to sys.path: {project_root}\")\n",
    "print(\"Current sys.path:\")\n",
    "for p in sys.path:\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from src.preprocess import clean_text\n",
    "\n",
    "if 'clean_text' in locals() and callable(clean_text):\n",
    "    print(\"clean_text is callable and loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: clean_text is not defined or not callable after import.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to save model to: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models\n",
      "Directory 'c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models' exists.\n",
      "'c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models' is a directory.\n",
      "Successfully wrote to 'c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models\\test_write.txt'. Write permissions are OK.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "models_dir_path = os.path.join(project_root, 'models')\n",
    "\n",
    "print(f\"Attempting to save model to: {models_dir_path}\")\n",
    "\n",
    "if os.path.exists(models_dir_path):\n",
    "    print(f\"Directory '{models_dir_path}' exists.\")\n",
    "    if os.path.isdir(models_dir_path):\n",
    "        print(f\"'{models_dir_path}' is a directory.\")\n",
    "        # Try creating a dummy file to test write permissions\n",
    "        try:\n",
    "            test_file_path = os.path.join(models_dir_path, 'test_write.txt')\n",
    "            with open(test_file_path, 'w') as f:\n",
    "                f.write(\"Test.\")\n",
    "            print(f\"Successfully wrote to '{test_file_path}'. Write permissions are OK.\")\n",
    "            os.remove(test_file_path) # Clean up\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing to directory: {e}. Permissions might be an issue.\")\n",
    "    else:\n",
    "        print(f\"ERROR: '{models_dir_path}' exists but is NOT a directory.\")\n",
    "else:\n",
    "    print(f\"ERROR: Directory '{models_dir_path}' does NOT exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a915046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.preprocess import clean_text\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caea1638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0567dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spam.csv', sep='\\t', header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "242ce607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_message'] = df['message'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd867777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels to numeric format\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd47e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message example: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "Cleaned message example: free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri questionstd txt ratetc appli 08452810075over18\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_message'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Original message example:\", df['message'][2])\n",
    "print(\"Cleaned message example:\", df['cleaned_message'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c64861e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3efccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train_cv = count_vectorizer.fit_transform(X_train)\n",
    "X_test_cv = count_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9526ae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Resampled distribution: label\n",
      "1    3859\n",
      "0    3859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm_cv = SMOTE(random_state=42)\n",
    "X_train_cv_res, y_train_cv_res = sm_cv.fit_resample(X_train_cv, y_train)\n",
    "print(f\"CV Resampled distribution: {pd.Series(y_train_cv_res).value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11bf7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidfvecorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d822a739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Resampled distribution: label\n",
      "1    3859\n",
      "0    3859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm_tfidf = SMOTE(random_state=42)\n",
    "X_train_tfidf_res, y_train_tfidf_res = sm_tfidf.fit_resample(X_train_tfidf, y_train)\n",
    "print(f\"TFIDF Resampled distribution: {pd.Series(y_train_tfidf_res).value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5260c735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_tfidf: (4457, 7142)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a028a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import train_model, evaluate_model, save_model\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da412784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b49a72ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Naive Bayes (CountVectorizer) Evaluation ---\n",
      "Accuracy: 0.9695\n",
      "Precision: 0.8662\n",
      "Recall: 0.9128\n",
      "F1 Score: 0.8889\n",
      "Confusion Matrix:\n",
      " [[945  21]\n",
      " [ 13 136]]\n",
      "Model saved to c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models\\nb_cv_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#naive bayes with countvectorizer\n",
    "nb_cv_model = train_model(X_train_cv_res, y_train_cv_res, model_name=\"MultinomialNB\")\n",
    "evaluate_model(nb_cv_model, X_test_cv, y_test, model_name=\"Naive Bayes (CountVectorizer)\")\n",
    "save_model(nb_cv_model, os.path.join(project_root, 'models', 'nb_cv_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e99da984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression (CountVectorizer) Evaluation ---\n",
      "Accuracy: 0.9211\n",
      "Precision: 0.6393\n",
      "Recall: 0.9396\n",
      "F1 Score: 0.7609\n",
      "Confusion Matrix:\n",
      " [[887  79]\n",
      " [  9 140]]\n",
      "Model saved to c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models\\lr_cv_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with count vectotizer\n",
    "lr_cv_model = train_model(X_train_cv_res, y_train_cv_res, model_name=\"LogisticRegression\")\n",
    "evaluate_model(lr_cv_model, X_test_cv, y_test, model_name=\"Logistic Regression (CountVectorizer)\")\n",
    "save_model(lr_cv_model, os.path.join(project_root, 'models', 'lr_cv_model.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad6486a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Naive Bayes (TfidfVectorizer) Evaluation ---\n",
      "Accuracy: 0.9740\n",
      "Precision: 0.8704\n",
      "Recall: 0.9463\n",
      "F1 Score: 0.9068\n",
      "Confusion Matrix:\n",
      " [[945  21]\n",
      " [  8 141]]\n",
      "Model saved to c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models\\nb_tfidf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#naive bayes with tfidf\n",
    "nb_tfidf_model = train_model(X_train_tfidf_res, y_train_tfidf_res, model_name=\"MultinomialNB\")\n",
    "evaluate_model(nb_tfidf_model, X_test_tfidf, y_test, model_name=\"Naive Bayes (TfidfVectorizer)\")\n",
    "save_model(nb_tfidf_model, os.path.join(project_root, 'models', 'nb_tfidf_model.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee17c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression (TfidfVectorizer) Evaluation ---\n",
      "Accuracy: 0.9803\n",
      "Precision: 0.9320\n",
      "Recall: 0.9195\n",
      "F1 Score: 0.9257\n",
      "Confusion Matrix:\n",
      " [[956  10]\n",
      " [ 12 137]]\n",
      "Model saved to c:\\Users\\asus\\OneDrive\\Desktop\\projects\\spam_classifier\\models\\lr_tfidf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#logistic regression with tfidf\n",
    "lr_tfidf_model = train_model(X_train_tfidf_res, y_train_tfidf_res, model_name=\"LogisticRegression\")\n",
    "evaluate_model(lr_tfidf_model, X_test_tfidf, y_test, model_name=\"Logistic Regression (TfidfVectorizer)\")\n",
    "save_model(lr_tfidf_model, os.path.join(project_root, 'models', 'lr_tfidf_model.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f61f994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer # Included for clarity of pipeline definition\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#import joblib\n",
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11267c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Starting Hyperparameter Tuning with GridSearchCV (using imblearn.Pipeline and SMOTE)...\")\n",
    "\n",
    "# # --- Define the Pipeline (using imblearn.pipeline.Pipeline) ---\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()), # Step 1: Text to numerical features\n",
    "#     ('smote', SMOTE(random_state=42)), # Step 2: Handle imbalance (applied on numerical data)\n",
    "#     ('lr', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)) # Step 3: Classification model\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a07c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'tfidf__max_features': [5000, 10000, None],\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "#     'tfidf__min_df': [1, 5, 10],\n",
    "#     'tfidf__max_df': [1.0, 0.9, 0.7],\n",
    "\n",
    "#     'smote__sampling_strategy': ['minority', 0.5, 1.0],\n",
    "#     'smote__k_neighbors': [3, 5, 7],\n",
    "\n",
    "#     'lr__C': [0.1, 1, 10, 100],\n",
    "#     'lr__solver': ['liblinear', 'saga'],\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bb97a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, n_jobs=-1, scoring='f1')\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7074e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nBest parameters found:\")\n",
    "# print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19816061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nBest F1-Score (from cross-validation):\")\n",
    "# print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a45f50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_pipeline = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3ea8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f16fbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = best_model.predict(X_test)\n",
    "# print(\"\\nClassification Report on Test Set (Best Model):\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecfb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nConfusion Matrix on Test Set (Best Model):\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f35b430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\asus\\\\OneDrive\\\\Desktop\\\\projects\\\\spam_classifier\\\\models\\\\tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(count_vectorizer, os.path.join(project_root, 'models', 'count_vectorizer.pkl'))\n",
    "joblib.dump(tfidf_vectorizer, os.path.join(project_root, 'models', 'tfidf_vectorizer.pkl')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d234bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(best_model_pipeline, os.path.join(project_root, 'models', 'best_lr_tfidf_smote_pipeline.pkl'))\n",
    "# print(f\"Best model pipeline saved to: {os.path.join(project_root, 'models', 'best_lr_tfidf_smote_pipeline.pkl')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53200d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top words for Logistic Regression (CountVectorizer) ---\n",
      "\n",
      "Top 20 words contributing to SPAM:\n",
      "         word  coefficient\n",
      "1775    claim     2.202755\n",
      "5535   servic     1.916296\n",
      "341        18     1.764362\n",
      "6465      txt     1.762666\n",
      "4225    mobil     1.682302\n",
      "6349     tone     1.526371\n",
      "5939     stop     1.524494\n",
      "5034    prize     1.520516\n",
      "5267    repli     1.484065\n",
      "5324  rington     1.452480\n",
      "2748  freemsg     1.425752\n",
      "6005      sue     1.412743\n",
      "1896  contact     1.365754\n",
      "1642     cash     1.321188\n",
      "4406      new     1.308708\n",
      "6182     text     1.240417\n",
      "6490       uk     1.224227\n",
      "1571     call     1.223478\n",
      "1926     cost     1.194051\n",
      "302       150     1.163459\n",
      "\n",
      "Top 20 words contributing to HAM:\n",
      "       word  coefficient\n",
      "4587     ok    -2.965973\n",
      "3953   ltgt    -2.954375\n",
      "5663    sir    -2.606108\n",
      "3337    ill    -2.413801\n",
      "3763  later    -2.327995\n",
      "2019     da    -2.317441\n",
      "3340     im    -2.272857\n",
      "4305   much    -2.215519\n",
      "6741    wat    -2.185886\n",
      "1839   come    -2.158885\n",
      "5929  still    -2.122354\n",
      "3204   home    -2.079649\n",
      "5801  sorri    -2.028285\n",
      "6923   work    -2.024281\n",
      "2908     go    -1.990386\n",
      "4703     pa    -1.989547\n",
      "4103   meet    -1.951341\n",
      "6789   well    -1.944463\n",
      "4593    oki    -1.931105\n",
      "3906    lor    -1.926953\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def show_top_words(model,vectorizer,top_n=20):\n",
    "    if not hasattr(model,'coef_'):\n",
    "        print(\"model does not have 'coef_' attribute.this is for logistic regression\")\n",
    "        return\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    coefs = model.coef_[0]\n",
    "    \n",
    "    word_coef_df = pd.DataFrame({'word': feature_names, 'coefficient': coefs})\n",
    "\n",
    "    # Sort for spam\n",
    "    top_spam_words = word_coef_df.sort_values(by='coefficient', ascending=False).head(top_n)\n",
    "    print(f\"\\nTop {top_n} words contributing to SPAM:\")\n",
    "    print(top_spam_words)\n",
    "    \n",
    "    #sort for ham\n",
    "    top_ham_words = word_coef_df.sort_values(by='coefficient', ascending=True).head(top_n)\n",
    "    print(f\"\\nTop {top_n} words contributing to HAM:\")\n",
    "    print(top_ham_words)\n",
    "    \n",
    "# with Logistic Regression (CountVectorizer)\n",
    "print(\"\\n--- Top words for Logistic Regression (CountVectorizer) ---\")\n",
    "show_top_words(lr_cv_model, count_vectorizer)\n",
    "\n",
    "# with Logistic Regression (TfidfVectorizer)\n",
    "#print(\"\\n--- Top words for Logistic Regression (TfidfVectorizer) ---\")\n",
    "#show_top_words(lr_tfidf_model, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfc6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
